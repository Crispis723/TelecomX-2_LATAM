# TelecomX â€“ PredicciÃ³n de CancelaciÃ³n de Clientes

Proyecto de **Data Science** para predecir la cancelaciÃ³n (churn) de clientes de una telco usando modelos de *Machine Learning* y un pipeline reproducible en Python / Colab.

---

## ğŸ§­ Objetivo

1. **Explorar** los datos y entender los principales factores asociados a la cancelaciÃ³n.
2. **Preparar** un pipeline robusto (limpieza â†’ encoding â†’ balanceo â†’ split â†’ escalado).
3. **Entrenar y evaluar** varios modelos (LogÃ­stica, Random Forest, KNN y SVM).
4. **Explicar** la relevancia de las variables (coeficientes, importancias y permutation importance).

---

## ğŸ“¦ Dataset

* Fuente: `TelecomX (1).csv` (repositorio original de Crispis723).
* Variable objetivo: `Cancelacion` (0 = activo, 1 = cancelÃ³).
* Variables numÃ©ricas: `Antiguedad`, `Cargos_Mensuales`, `Cargos_Totales`, `Cargo_Diario`, etc.
* Variables categÃ³ricas: **servicios**, **tipo de contrato**, **mÃ©todo de pago**, **gÃ©nero**, etc.
* Identificador Ãºnico: `customerID` (**se elimina**).

> âš ï¸ **Importante:** eliminar `customerID` **antes** de hacer `get_dummies` para no crear miles de columnas inÃºtiles.

---

## ğŸ§° Requisitos

```bash
python >= 3.9
pip install -r requirements.txt
```

`requirements.txt` sugerido:

```
pandas
numpy
scikit-learn
imbalanced-learn
matplotlib
seaborn
```

---

## ğŸ—‚ï¸ Estructura recomendada del repo

```
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ TelecomX (1).csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Copia_de_TelecomX2_LATAM.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ telecomx_pipeline.py   # (opcional) versiÃ³n script
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figs/                  # grÃ¡ficos exportados
â”‚   â””â”€â”€ models/                # modelos serializados (opcional)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ CÃ³mo ejecutar

### OpciÃ³n A â€” Google Colab (recomendada)

1. Abre el notebook `notebooks/Copia_de_TelecomX2_LATAM.ipynb` en Colab.
2. Ejecuta las celdas en orden (ya incluye carga desde GitHub).

### OpciÃ³n B â€” Local

```bash
git clone <tu-repo>
cd <tu-repo>
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
jupyter notebook notebooks/Copia_de_TelecomX2_LATAM.ipynb
```

---

## ğŸ§ª Pipeline (resumen)

1. **Carga** y vista general (`df.info()`, nulos, duplicados).
2. **Limpieza**

   * Drop: `customerID`.
   * ConversiÃ³n booleana â†’ numÃ©rica: `{True/False/"true"/"false"} â†’ {1/0}`.
3. **Encoding**

   * `get_dummies` sobre columnas `object` con `drop_first=True`.
4. **Split**

   * `train_test_split` con `stratify=y`, test=0.30.
   * Alinear columnas: `X_test = X_test.reindex(columns=X_train.columns, fill_value=0)`.
5. **Balanceo (solo en train)**

   * SMOTE por defecto; opciÃ³n de `RandomUnderSampler`.
6. **Escalado (solo modelos sensibles a escala)**

   * `StandardScaler` **fit** en `X_train_res` y **transform** en `X_train_res` y `X_test`.
7. **Modelado**

   * LogÃ­stica (escalada).
   * Random Forest (sin escalar).
   * KNN (escalado).
   * SVM lineal (escalado).
8. **OptimizaciÃ³n**

   * `GridSearchCV` para Random Forest (y opcional para LogÃ­stica/SVM).
9. **EvaluaciÃ³n**

   * Accuracy, Precision, Recall, F1 y matriz de confusiÃ³n.
10. **Explicabilidad**

    * LogÃ­stica/SVM: coeficientes.
    * Random Forest: `feature_importances_`.
    * KNN: `permutation_importance`.
    * **Tabla comparativa normalizada** (promedio entre modelos).

---

## ğŸ“ˆ GrÃ¡ficos clave

* **EDA**

  * Heatmap de correlaciÃ³n (columna `Cancelacion`).
  * Boxplots: `Antiguedad Ã— Cancelacion`, `Cargos_Totales Ã— Cancelacion`.
  * Scatter: `Antiguedad` vs `Cargos_Totales` (hue = `Cancelacion`).

* **Modelos**

  * Matrices de confusiÃ³n (LogÃ­stica / RF / RF Optimizado).
  * Importancia de variables:

    * LogÃ­stica: barras de coeficientes.
    * SVM lineal: barras de coeficientes.
    * Random Forest: barras `feature_importances_`.
    * KNN: *Permutation Importance*.
  * **Resumen final**: barras con el **promedio normalizado de importancia** entre modelos.

> Tip visual: usa 12â€“15 variables top por grÃ¡fico para evitar ruido.

---

## âœ… Buenas prÃ¡cticas y â€œgotchasâ€

* **No SMOTE en test** (solo en entrenamiento).
* **Escala** Ãºnicamente para LogÃ­stica/KNN/SVM. Los Ã¡rboles no lo requieren.
* **Columnas consistentes** entre train y test (`reindex`).
* **Booleans a int** tras `get_dummies`:

  ```python
  df_encoded = df_encoded.replace({True: 1, False: 0, "true": 1, "false": 0})
  ```
* **MÃ©tricas balanceadas**: si el desbalance es alto, prioriza **Recall** y **F1** ademÃ¡s de Accuracy.
* **Umbral de decisiÃ³n**: considera ajustar el umbral (0.5 â†’ 0.4/0.6) segÃºn el costo de falsos negativos/positivos.

---

## ğŸ§  Hallazgos (resumen interpretativo)

* **Costos** (`Cargos_Mensuales` y `Cargo_Diario`) son los predictores mÃ¡s fuertes de cancelaciÃ³n.
* **AntigÃ¼edad** reduce la probabilidad de cancelar (fuerte en modelos de Ã¡rboles).
* **Contratos de 1 y 2 aÃ±os** estÃ¡n asociados a menor churn vs. contratos mensuales.
* **Servicio de Internet**: *Fiber optic* suele asociarse a mayor probabilidad de churn (mayores expectativas); *No internet* tiende a menor churn.
* **Servicios adicionales** (Seguridad/Soporte/Respaldo) y **mÃ©todos de pago** aportan informaciÃ³n secundaria Ãºtil.

> Estos patrones son consistentes entre modelos (LogÃ­stica, RF, KNN y SVM), lo que refuerza su validez.

---

## ğŸ“Š CÃ³mo reproducir las tablas/grÃ¡ficos de importancia

En el notebook ya estÃ¡n los bloques para:

* Coeficientes (LogÃ­stica/SVM).
* `feature_importances_` (RF).
* `permutation_importance` (KNN).
* **DataFrame comparativo normalizado** y **ranking global** por promedio.

---

## ğŸ”® PrÃ³ximos pasos

* CalibraciÃ³n de probabilidades (Platt / IsotÃ³nica) para mejores umbrales.
* Curvas **ROC/PR** y **AUC** para comparar modelos.
* **XGBoost / LightGBM** y *RandomizedSearchCV* para mejorar tiempo de bÃºsqueda.
* *SHAP values* para explicabilidad local y auditorÃ­a de sesgos.
* SegmentaciÃ³n de clientes (clustering) para estrategias de retenciÃ³n diferenciadas.

---


Si quieres, puedo convertir este README en **versiÃ³n inglesa** y generar un **badge set** (build, license, python version) y un **Makefile** con comandos (`make setup`, `make train`, `make report`).
